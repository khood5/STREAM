{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LangDataloader import LangDataloader\n",
    "from LangDataloader import addData\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_lmu \n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "defultePlotSize = plt.rcParams['figure.figsize']\n",
    "oringalFontSize = matplotlib.rcParams['font.size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "# sess.as_default()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only load a subset of the total dataset to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LangDataloader(\"/home/khood/GitHub/STREAM/Prepocessing/processedData/index.csv\", \"/home/khood/GitHub/STREAM/Prepocessing/processedData\")\n",
    "rawData = []\n",
    "lastStep = 0\n",
    "labelToNum = {}\n",
    "num = 0\n",
    "for step in list(range(0,len(data),100)):\n",
    "    for file in range(len(data))[lastStep:step]:\n",
    "        print(f\"adding {lastStep} to {step} of {len(data)}: {'{0:.0f}%'.format(step/len(data) * 100)}... \",end=\"\\x1b\\r\")\n",
    "        label = None\n",
    "        if data[file][1][0] in labelToNum.keys():\n",
    "            label = np.array([labelToNum[data[file][1][0]]])\n",
    "        else:\n",
    "            labelToNum[data[file][1][0]] = num\n",
    "            num = num + 1\n",
    "            label = np.array([labelToNum[data[file][1][0]]])\n",
    "            \n",
    "        melspectrogram = np.array([data[file][0]]).flatten()\n",
    "        melspectrogram = [[i] for i in melspectrogram]\n",
    "        rawData.append([melspectrogram, label])\n",
    "        \n",
    "    lastStep = step\n",
    "        \n",
    "# for file in range(len(data))[lastStep:]: # grab the remaning (if the size%stepSize != 0 then there will be some left over)\n",
    "#     print(f\"adding {lastStep} to {len(data)} of {len(data)}: {'{0:.0f}%'.format(step/len(data) * 100)}... \",end=\"\\x1b\\r\")\n",
    "#     rawData.append(data[file])\n",
    "    \n",
    "rawData[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert targets to numbers classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelToNum.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension should be time, the second to last should be the n_mels\n",
    "\n",
    "<p>not flattened shape: (1, 128, 430)\n",
    "<p>flattened shape: (55040,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = 55040\n",
    "\n",
    "lmu_layer = keras_lmu.LMU(\n",
    "    memory_d=1,\n",
    "    order=256,\n",
    "    theta=n_pixels,\n",
    "    hidden_cell=tf.keras.layers.SimpleRNNCell(2750),\n",
    "    hidden_to_memory=False,\n",
    "    memory_to_memory=False,\n",
    "    input_to_hidden=True,\n",
    "    kernel_initializer=\"ones\",\n",
    ")\n",
    "\n",
    "# TensorFlow layer definition\n",
    "inputs = tf.keras.Input((n_pixels, 1))\n",
    "lmus = lmu_layer(inputs)\n",
    "outputs = tf.keras.layers.Dense(len(labelToNum.keys()))(lmus)\n",
    "\n",
    "# TensorFlow model definition\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = []\n",
    "train = []\n",
    "addData(valid, train, rawData, int(len(rawData)*0.9))\n",
    "print(f\"Train: {len(train)}\")\n",
    "print(f\"Valid: {len(valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for i in train:\n",
    "    X_train.append(np.array(i[0]))\n",
    "    Y_train.append(i[0][0][0])\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Y_train size: {len(Y_train)}, X_train size: {len(X_train)}\")\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train[0]))\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train)\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "Y_valid = []\n",
    "for i in valid:\n",
    "    X_valid.append(i[0])\n",
    "    Y_valid.append(i[0][0])\n",
    "X_valid=np.array(X_valid)\n",
    "Y_valid=np.array(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = True\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "saved_weights_fname = \"./psMNIST-weights.hdf5\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=saved_weights_fname, monitor=\"val_loss\", verbose=1, save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "result = None\n",
    "if do_training:\n",
    "    result = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_valid, Y_valid),\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_lmu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
